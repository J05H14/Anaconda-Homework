{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\j05h1\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2785: DtypeWarning: Columns (25,51) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "pd.get_option(\"display.max_rows\", None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "nfl_data = pd.read_csv(\"NFL Play by Play 2009-2017 (v4).csv\")\n",
    "toDelete = ['ExPointResult','TwoPointConv','DefTwoPoint','Safety','Onsidekick','Passer','Passer_ID','QBHit','PassLocation','Interceptor','Rusher','Rusher_ID'\n",
    ",'RunLocation','RunGap','Receiver','Receiver_ID','ReturnResult','Returner','BlockingPlayer','Tackler1','Tackler2','Challenge.Replay','ChalReplayResult'\n",
    ",'Accepted.Penalty','PenalizedTeam','PenaltyType','PenalizedPlayer','Penalty.Yards','HomeTeam','AwayTeam','Timeout_Indicator','Timeout_Team','posteam_timeouts_pre'\n",
    ",'HomeTimeouts_Remaining_Pre','AwayTimeouts_Remaining_Pre','HomeTimeouts_Remaining_Post','AwayTimeouts_Remaining_Post','No_Score_Prob','Opp_Field_Goal_Prob'\n",
    ",'Opp_Safety_Prob','Opp_Touchdown_Prob','Field_Goal_Prob','Safety_Prob','Touchdown_Prob','ExPoint_Prob','TwoPoint_Prob','ExpPts','EPA','airEPA','yacEPA'\n",
    ",'Home_WP_pre','Away_WP_pre','Home_WP_post','Away_WP_post','Win_Prob','WPA','airWPA','yacWPA','SideofField','sp','PuntResult','RecFumbTeam','RecFumbPlayer'\n",
    ",'AbsScoreDiff','FieldGoalDistance','TimeUnder','posteam','DefensiveTeam','PlayAttempted','FieldGoalResult','Sack','RushAttempt','PassAttempt','ScoreDiff'\n",
    ", 'desc', 'Date', 'GameID', 'Season', 'PassOutcome', 'PassLength', 'AirYards', 'YardsAfterCatch', 'yrdln', 'time',]\n",
    "\n",
    "for x in toDelete:\n",
    "    del nfl_data[x]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(346515, 18)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = nfl_data.dropna()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorical_to_numeric(x):\n",
    "    if x == 'No Play':\n",
    "        return 0\n",
    "    elif x == 'Run':\n",
    "        return 1\n",
    "    elif x == 'Pass':\n",
    "        return 2\n",
    "    elif x == 'Timeout':\n",
    "        return 3\n",
    "    elif x == 'Punt':\n",
    "        return 4\n",
    "    elif x == 'Field Goal':\n",
    "        return 5\n",
    "    elif x == 'Sack':\n",
    "        return 6\n",
    "    elif x == 'QB Kneel':\n",
    "        return 7\n",
    "    elif x == 'Spike':\n",
    "        return 8\n",
    "    elif x == 'Kickoff':\n",
    "        return 9\n",
    "    elif x == 'Half End':\n",
    "        return 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\j05h1\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "features = ['Drive', 'qtr', 'down', 'TimeSecs', 'PlayTimeDiff', 'yrdline100', 'ydstogo', 'ydsnet', 'GoalToGo', 'FirstDown', 'Yards.Gained', 'PosTeamScore', 'DefTeamScore']\n",
    "df['Label'] = df['PlayType'].apply(categorical_to_numeric)\n",
    "X = df[features]\n",
    "y = df['Label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.075, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy: 0.6856747085305321\n"
     ]
    }
   ],
   "source": [
    "#creating the decision tree\n",
    "my_DecisionTree = DecisionTreeClassifier(random_state=1)\n",
    "#training the decision tree\n",
    "my_DecisionTree.fit(X_train, y_train)\n",
    "#predict y using decision tree\n",
    "y_predict_dt = my_DecisionTree.predict(X_test)\n",
    "#obtain score for decision tree\n",
    "dt_score = accuracy_score(y_test, y_predict_dt)\n",
    "print (\"Decision Tree Accuracy: \" + str(dt_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Score: 0.7752125899418985\n"
     ]
    }
   ],
   "source": [
    "#the random forest classifier\n",
    "my_RandomForest = RandomForestClassifier(n_estimators = 64, bootstrap = True, random_state=3)\n",
    "#Training and Predicting using Random Forest\n",
    "my_RandomForest.fit(X_train, y_train)\n",
    "y_predict_rf = my_RandomForest.predict(X_test)\n",
    "\n",
    "#calculating accuracy score of random forest\n",
    "rf_score = accuracy_score(y_test, y_predict_rf)\n",
    "\n",
    "#print random forest score\n",
    "print(\"Random Forest Score: \" + str(rf_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.6310362076263034\n"
     ]
    }
   ],
   "source": [
    "#predict using logistic regression\n",
    "\n",
    "#create the Logistic Regression Classifier\n",
    "lr = LogisticRegression()\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "#predict y with logistic regression\n",
    "y_predict_lr = lr.predict(X_test)\n",
    "\n",
    "#get the logistic regression's score\n",
    "lr_score = accuracy_score(y_test, y_predict_lr)\n",
    "\n",
    "print(\"Logistic Regression Accuracy: \" + str(lr_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy: 0.6856747085305321\n",
      "Random Forest Accuracy: 0.7752125899418985\n",
      "Logistic Regression Accuracy: 0.6310362076263034\n"
     ]
    }
   ],
   "source": [
    "print (\"Decision Tree Accuracy: \" + str(dt_score))\n",
    "print(\"Random Forest Accuracy: \" + str(rf_score))\n",
    "print(\"Logistic Regression Accuracy: \" + str(lr_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00000000e+00 0.00000000e+00 5.91540964e-05 ... 9.98580302e-01\n",
      " 9.98580302e-01 1.00000000e+00]\n",
      "[1.10083664e-04 7.70585645e-04 7.70585645e-04 ... 9.99889916e-01\n",
      " 1.00000000e+00 1.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "y_predict_prob_lr = lr.predict_proba(X_test)\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_predict_prob_lr[:,1], pos_label=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'metrics' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-e3aed2ade207>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mAUC\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Area Under the Curve: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mAUC\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'metrics' is not defined"
     ]
    }
   ],
   "source": [
    "AUC = auc(fpr, tpr)\n",
    "print(\"Area Under the Curve: \" + str(AUC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
