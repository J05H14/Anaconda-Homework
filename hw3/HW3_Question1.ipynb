{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the Hear_s csv file\n",
    "df = pd.read_csv(\"Heart_s.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Age Gender     ChestPain  RestBP  Chol  RestECG  MaxHR  Oldpeak  \\\n",
      "0     63      f       typical     145   233        2    150      2.3   \n",
      "1     67      f  asymptomatic     160   286        2    108      1.5   \n",
      "2     67      f  asymptomatic     120   229        2    129      2.6   \n",
      "3     37      f    nonanginal     130   250        0    187      3.5   \n",
      "4     41      m    nontypical     130   204        2    172      1.4   \n",
      "5     56      f    nontypical     120   236        0    178      0.8   \n",
      "6     62      m  asymptomatic     140   268        2    160      3.6   \n",
      "7     57      m  asymptomatic     120   354        0    163      0.6   \n",
      "8     63      f  asymptomatic     130   254        2    147      1.4   \n",
      "9     53      f  asymptomatic     140   203        2    155      3.1   \n",
      "10    57      f  asymptomatic     140   192        0    148      0.4   \n",
      "11    56      m    nontypical     140   294        2    153      1.3   \n",
      "12    56      f    nonanginal     130   256        2    142      0.6   \n",
      "13    44      f    nontypical     120   263        0    173      0.0   \n",
      "14    52      f    nonanginal     172   199        0    162      0.5   \n",
      "15    57      f    nonanginal     150   168        0    174      1.6   \n",
      "16    48      f    nontypical     110   229        0    168      1.0   \n",
      "17    54      f  asymptomatic     140   239        0    160      1.2   \n",
      "18    48      m    nonanginal     130   275        0    139      0.2   \n",
      "19    49      f    nontypical     130   266        0    171      0.6   \n",
      "20    64      f       typical     110   211        2    144      1.8   \n",
      "21    58      m       typical     150   283        2    162      1.0   \n",
      "22    58      f    nontypical     120   284        2    160      1.8   \n",
      "23    58      f    nonanginal     132   224        2    173      3.2   \n",
      "24    60      f  asymptomatic     130   206        2    132      2.4   \n",
      "25    50      m    nonanginal     120   219        0    158      1.6   \n",
      "26    58      m    nonanginal     120   340        0    172      0.0   \n",
      "27    66      m       typical     150   226        0    114      2.6   \n",
      "28    43      f  asymptomatic     150   247        0    171      1.5   \n",
      "29    40      f  asymptomatic     110   167        2    114      2.0   \n",
      "..   ...    ...           ...     ...   ...      ...    ...      ...   \n",
      "271   71      m  asymptomatic     112   149        0    125      1.6   \n",
      "272   59      f       typical     134   204        0    162      0.8   \n",
      "273   64      f       typical     170   227        2    155      0.6   \n",
      "274   66      m    nonanginal     146   278        2    152      0.0   \n",
      "275   39      m    nonanginal     138   220        0    152      0.0   \n",
      "276   57      f    nontypical     154   232        2    164      0.0   \n",
      "277   58      m  asymptomatic     130   197        0    131      0.6   \n",
      "278   57      f  asymptomatic     110   335        0    143      3.0   \n",
      "279   47      f    nonanginal     130   253        0    179      0.0   \n",
      "280   55      m  asymptomatic     128   205        1    130      2.0   \n",
      "281   35      f    nontypical     122   192        0    174      0.0   \n",
      "282   61      f  asymptomatic     148   203        0    161      0.0   \n",
      "283   58      f  asymptomatic     114   318        1    140      4.4   \n",
      "284   58      m  asymptomatic     170   225        2    146      2.8   \n",
      "285   58      f    nontypical     125   220        0    144      0.4   \n",
      "286   56      f    nontypical     130   221        2    163      0.0   \n",
      "287   56      f    nontypical     120   240        0    169      0.0   \n",
      "288   67      f    nonanginal     152   212        2    150      0.8   \n",
      "289   55      m    nontypical     132   342        0    166      1.2   \n",
      "290   44      f  asymptomatic     120   169        0    144      2.8   \n",
      "291   63      f  asymptomatic     140   187        2    144      4.0   \n",
      "292   63      m  asymptomatic     124   197        0    136      0.0   \n",
      "293   41      f    nontypical     120   157        0    182      0.0   \n",
      "294   59      f  asymptomatic     164   176        2     90      1.0   \n",
      "295   57      m  asymptomatic     140   241        0    123      0.2   \n",
      "296   45      f       typical     110   264        0    132      1.2   \n",
      "297   68      f  asymptomatic     144   193        0    141      3.4   \n",
      "298   57      f  asymptomatic     130   131        0    115      1.2   \n",
      "299   57      m    nontypical     130   236        2    174      0.0   \n",
      "300   38      f    nonanginal     138   175        0    173      0.0   \n",
      "\n",
      "           Thal  AHD  \n",
      "0         fixed   No  \n",
      "1        normal  Yes  \n",
      "2    reversable  Yes  \n",
      "3        normal   No  \n",
      "4        normal   No  \n",
      "5        normal   No  \n",
      "6        normal  Yes  \n",
      "7        normal   No  \n",
      "8    reversable  Yes  \n",
      "9    reversable  Yes  \n",
      "10        fixed   No  \n",
      "11       normal   No  \n",
      "12        fixed  Yes  \n",
      "13   reversable   No  \n",
      "14   reversable   No  \n",
      "15       normal   No  \n",
      "16   reversable  Yes  \n",
      "17       normal   No  \n",
      "18       normal   No  \n",
      "19       normal   No  \n",
      "20       normal   No  \n",
      "21       normal   No  \n",
      "22       normal  Yes  \n",
      "23   reversable  Yes  \n",
      "24   reversable  Yes  \n",
      "25       normal   No  \n",
      "26       normal   No  \n",
      "27       normal   No  \n",
      "28       normal   No  \n",
      "29   reversable  Yes  \n",
      "..          ...  ...  \n",
      "271      normal   No  \n",
      "272      normal  Yes  \n",
      "273  reversable   No  \n",
      "274      normal   No  \n",
      "275      normal   No  \n",
      "276      normal  Yes  \n",
      "277      normal   No  \n",
      "278  reversable  Yes  \n",
      "279      normal   No  \n",
      "280  reversable  Yes  \n",
      "281      normal   No  \n",
      "282  reversable  Yes  \n",
      "283       fixed  Yes  \n",
      "284       fixed  Yes  \n",
      "285  reversable   No  \n",
      "286  reversable   No  \n",
      "287      normal   No  \n",
      "288  reversable  Yes  \n",
      "289      normal   No  \n",
      "290       fixed  Yes  \n",
      "291  reversable  Yes  \n",
      "292      normal  Yes  \n",
      "293      normal   No  \n",
      "294       fixed  Yes  \n",
      "295  reversable  Yes  \n",
      "296  reversable  Yes  \n",
      "297  reversable  Yes  \n",
      "298  reversable  Yes  \n",
      "299      normal  Yes  \n",
      "300      normal   No  \n",
      "\n",
      "[301 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df) # print dataframe to see the contents of it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#got the columns of fetures\n",
    "num_feature_cols = ['Age','RestBP','Chol','RestECG', 'MaxHR', 'Oldpeak']\n",
    "#data frame with the fetures\n",
    "X = df[num_feature_cols]  \n",
    "\n",
    "#series with labels\n",
    "y = df['AHD']\n",
    "\n",
    "#getting sklearn for spliting\n",
    "from sklearn.model_selection import train_test_split\n",
    "#splitting the data into trainning and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict using knn classifier\n",
    "\n",
    "#import the k neighbors classifier from sklearn\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "k = 3 #set k = 3\n",
    "\n",
    "#Create the KNN Classifier\n",
    "knn = KNeighborsClassifier(n_neighbors = k)\n",
    "\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "#predicting y using knn\n",
    "y_predict_knn = knn.predict(X_test)\n",
    "\n",
    "#get sklearn for getting the accuracy of the prediction\n",
    "from sklearn.metrics import accuracy_score\n",
    "#using the accuracy_score function to find out how accurate the knn was\n",
    "knn_score = accuracy_score(y_test, y_predict_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict using decision tree classifier\n",
    "\n",
    "#import the decision tree classifier from sklearn\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "#creating the decision tree\n",
    "dt = DecisionTreeClassifier(random_state=5)\n",
    "\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "#predict y using decision tree\n",
    "y_predict_dt = dt.predict(X_test)\n",
    "#obtain score for decision tree\n",
    "dt_score = accuracy_score(y_test, y_predict_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict using logistic regression\n",
    "\n",
    "#import logistic regression from sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#create the Logistic Regression Classifier\n",
    "lr = LogisticRegression()\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "#predict y with logistic regression\n",
    "y_predict_lr = lr.predict(X_test)\n",
    "#get the logistic regression's score\n",
    "lr_score = accuracy_score(y_test, y_predict_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN CLassifier: 0.6973684210526315\n",
      "Decision Tree Classifier: 0.6052631578947368\n",
      "Logistic Regression Classifier: 0.7236842105263158\n"
     ]
    }
   ],
   "source": [
    "#printing out the various scores for each classifier\n",
    "print(\"KNN CLassifier: \" + str(knn_score))\n",
    "print(\"Decision Tree Classifier: \" + str(dt_score))\n",
    "print(\"Logistic Regression Classifier: \" + str(lr_score))\n",
    "#Of the three, classifiers, Logistic regression resulted with the best results, \n",
    "#while decision tree classifier had the worst score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OneHotEncoding\n",
    "\n",
    "#function to change the value of a column into a numeric\n",
    "#if it is the value it becomes 1 and if it isn't it is 0\n",
    "def change_to_numeric(data, value):\n",
    "    numeric_list = list()\n",
    "    for item in data:\n",
    "        if item == value:\n",
    "            numeric_list.append(1) #value of 1 if it contains the value\n",
    "        else:\n",
    "            numeric_list.append(0) #value of 0 if it doesnt contain the value\n",
    "    return numeric_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change values of genders into numeric\n",
    "ohe_gender_m = change_to_numeric(df['Gender'], 'm')\n",
    "ohe_gender_f = change_to_numeric(df['Gender'], 'f')\n",
    "\n",
    "#changing chest pain into numerical values\n",
    "ohe_pain_typ = change_to_numeric(df['ChestPain'], 'typical')\n",
    "ohe_pain_asym = change_to_numeric(df['ChestPain'], 'asymptomatic')\n",
    "ohe_pain_nona = change_to_numeric(df['ChestPain'], 'nonanginal')\n",
    "ohe_pain_nont = change_to_numeric(df['ChestPain'], 'nontypical')\n",
    "        \n",
    "\n",
    "#changing Thal into numerical values\n",
    "ohe_thal_normal = change_to_numeric(df['Thal'], 'normal')\n",
    "ohe_thal_fix = change_to_numeric(df['Thal'], 'fixed')\n",
    "ohe_thal_rev = change_to_numeric(df['Thal'], 'reversable')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a dataframe with all numerical data\n",
    "full_df = pd.DataFrame({'Age':df['Age'], 'RestBP':df['RestBP'], 'Chol':df['Chol'], 'RestECG':df['RestECG'], 'MaxHR':df['MaxHR'], 'Oldpeak':df['Oldpeak'], 'Male':ohe_gender_m, 'Female':ohe_gender_f, 'Typical':ohe_pain_typ, 'Asymptomatic':ohe_pain_asym, 'Nonangial':ohe_pain_nona, 'Nontypical':ohe_pain_nont, 'Normal':ohe_thal_normal, 'Fixed':ohe_thal_fix, 'Reversable':ohe_thal_rev})\n",
    "\n",
    "#repeat part d with new dataframe\n",
    "X = full_df  \n",
    "\n",
    "#series with labels\n",
    "y = df['AHD']\n",
    "\n",
    "#splitting the data into trainning and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting with KNN Classifier using new data\n",
    "#fitting\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "#predicting y\n",
    "y_predict_knn = knn.predict(X_test)\n",
    "\n",
    "#calculate knn's score\n",
    "knn_score = accuracy_score(y_test, y_predict_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting with Decision Tree Classifier using new data\n",
    "\n",
    "#creating the decision tree w/ random state 5\n",
    "dt = DecisionTreeClassifier(random_state=5)\n",
    "\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "y_predict_dt = dt.predict(X_test)\n",
    "\n",
    "#calculate dt's score\n",
    "dt_score = accuracy_score(y_test, y_predict_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting with Logistic Regression using new data\n",
    "\n",
    "#create the Logistic Regression Classifier\n",
    "lr = LogisticRegression()\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "y_predict_lr = lr.predict(X_test)\n",
    "\n",
    "#calculate lr's score\n",
    "lr_score = accuracy_score(y_test, y_predict_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN CLassifier: 0.6973684210526315\n",
      "Decision Tree Classifier: 0.6842105263157895\n",
      "Logistic Regression Classifier: 0.8026315789473685\n"
     ]
    }
   ],
   "source": [
    "#printing out the various scores for each classifier\n",
    "print(\"KNN CLassifier: \" + str(knn_score))\n",
    "print(\"Decision Tree Classifier: \" + str(dt_score))\n",
    "print(\"Logistic Regression Classifier: \" + str(lr_score))\n",
    "#Of the three, classifiers, Logistic regression still resulted with the best \n",
    "#results, while decision tree classifier remained with the worst score\n",
    "#the new bits of data did not affect the ranking of the three classifiers\n",
    "#but they each improved from the original score. KNN and Decision Tree only\n",
    "#increased a little, but Linear Regression saw a much larger increase in its score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing cross validation from sklearn\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Cross Validation: 0.6246829810901001\n",
      "Decision Tree Cross Validation: 0.7173007044864664\n",
      "Logistic Regression Cross Validation: 0.8138895068594735\n"
     ]
    }
   ],
   "source": [
    "#Getting Cross Validation Score for KNN Classifier\n",
    "knn_acc_list = cross_val_score(knn, X, y, cv=10, scoring='accuracy')\n",
    "knn_acc_cv = knn_acc_list.mean()\n",
    "\n",
    "#Getting Cross Validation Score for Decision Tree Classifier\n",
    "dt_acc_list = cross_val_score(dt, X, y, cv=10, scoring='accuracy')\n",
    "dt_acc_cv = dt_acc_list.mean()\n",
    "\n",
    "#Getting Cross Validation Score for Logistic Regression Classifier\n",
    "lr_acc_list = cross_val_score(lr, X, y, cv=10, scoring='accuracy')\n",
    "lr_acc_cv = lr_acc_list.mean()\n",
    "print(\"KNN Cross Validation: \" + str(knn_acc_cv))\n",
    "print(\"Decision Tree Cross Validation: \" + str(dt_acc_cv))\n",
    "print(\"Logistic Regression Cross Validation: \" + str(lr_acc_cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
